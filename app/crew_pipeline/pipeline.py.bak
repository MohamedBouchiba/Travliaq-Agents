"""Pipeline CrewAI refactoris√©e pour la Phase 1 : Analyse & Sp√©cifications (YAML Only)."""

from __future__ import annotations

import json
import logging
import os
import re
from copy import deepcopy
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional
from uuid import uuid4

import yaml
from crewai import Agent, Crew, Process, Task
from crewai import LLM

from app.config import settings
from app.crew_pipeline.mcp_tools import get_mcp_tools
from app.crew_pipeline.observability import (
    PipelineMetrics,
    log_structured_input,
    log_structured_output,
)

logger = logging.getLogger(__name__)


@dataclass
class CrewPipelineResult:
    """R√©sultat structur√© de la pipeline (Phase 1)."""
    run_id: str
    status: str
    normalized_trip_request: Dict[str, Any] = field(default_factory=dict)
    tasks_output: List[Dict[str, Any]] = field(default_factory=list)
    raw_output: str = ""

    def to_dict(self) -> Dict[str, Any]:
        return {
            "run_id": self.run_id,
            "status": self.status,
            "normalized_trip_request": self.normalized_trip_request,
            "tasks_output": self.tasks_output,
            "raw_output": self.raw_output,
        }


class CrewPipeline:
    """
    Orchestrateur de la Phase 1 : Analyse & Sp√©cifications.
    
    Flux :
    1. Traveller Insights Analyst (avec MCP)
    2. Persona Quality Challenger (avec MCP)
    3. Trip Specifications Architect
    
    Format : YAML strict.
    """

    def __init__(
        self,
        *,
        llm: Optional[LLM] = None,
        verbose: Optional[bool] = None,
        output_dir: Optional[Path] = None,
    ) -> None:
        self._llm = llm or self._build_default_llm()
        self._verbose = verbose if verbose is not None else settings.verbose
        self._output_dir = Path(output_dir) if output_dir is not None else Path(settings.crew_output_dir)
        self._config_dir = Path(__file__).resolve().parent / "config"

    def run(
        self,
        *,
        questionnaire_data: Dict[str, Any],
        persona_inference: Dict[str, Any],
        payload_metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Ex√©cute la pipeline Phase 1."""
        
        # 1. Pr√©paration des donn√©es (Conversion YAML pour le contexte)
        run_id = self._generate_run_id(questionnaire_data)
        logger.info(f"üöÄ Lancement Pipeline Phase 1 (Run ID: {run_id})")

        # On convertit les inputs en YAML string pour que les agents les lisent facilement
        questionnaire_yaml = yaml.dump(questionnaire_data, allow_unicode=True, sort_keys=False)
        persona_yaml = yaml.dump(persona_inference, allow_unicode=True, sort_keys=False)

        # 2. Chargement de la configuration
        agents_config = self._load_yaml_config("agents.yaml")
        tasks_config = self._load_yaml_config("tasks.yaml")

        # 3. Chargement des outils MCP
        mcp_tools = []
        if settings.mcp_server_url:
            try:
                mcp_tools = get_mcp_tools(settings.mcp_server_url)
                logger.info(f"‚úÖ {len(mcp_tools)} outils MCP charg√©s.")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur chargement MCP: {e}")

        # 4. Cr√©ation des Agents
        # Agent 1: Analyst
        analyst = self._create_agent(
            "traveller_insights_analyst", 
            agents_config["traveller_insights_analyst"], 
            tools=mcp_tools # MCP Obligatoire
        )
        
        # Agent 2: Challenger
        challenger = self._create_agent(
            "persona_quality_challenger", 
            agents_config["persona_quality_challenger"], 
            tools=mcp_tools # MCP Obligatoire
        )
        
        # Agent 3: Architect
        architect = self._create_agent(
            "trip_specifications_architect", 
            agents_config["trip_specifications_architect"],
            tools=[] # Pas d'outils MCP n√©cessaires pour la structure
        )

        # 5. Cr√©ation des T√¢ches
        task1 = Task(
            name="traveller_profile_brief",
            agent=analyst,
            **tasks_config["traveller_profile_brief"]
        )
        
        task2 = Task(
            name="persona_challenge_review",
            agent=challenger,
            context=[task1],
            **tasks_config["persona_challenge_review"]
        )
        
        task3 = Task(
            name="trip_specifications_design",
            agent=architect,
            context=[task2],
            **tasks_config["trip_specifications_design"]
        )

        # 6. Assemblage et Ex√©cution de la Crew
        crew = Crew(
            agents=[analyst, challenger, architect],
            tasks=[task1, task2, task3],
            verbose=self._verbose,
            process=Process.sequential
        )

        # Inputs pour l'interpolation dans les descriptions des t√¢ches
        inputs = {
            "questionnaire": questionnaire_yaml,
            "persona_context": persona_yaml,
            "input_payload": yaml.dump({
                "questionnaire": questionnaire_data, 
                "persona": persona_inference
            }, allow_unicode=True) # Pour l'architecte qui veut tout
        }

        try:
            output = crew.kickoff(inputs=inputs)
        except Exception as exc:
            logger.exception("‚ùå √âchec critique de la pipeline")
            raise exc

        # 7. Traitement des Outputs (Parsing & Sauvegarde)
        final_result = self._process_outputs(run_id, output, questionnaire_data, persona_inference)
        
        return final_result

    def _create_agent(self, name: str, config: Dict[str, Any], tools: List[Any]) -> Agent:
        """Cr√©e un agent avec sa configuration et ses outils."""
        return Agent(
            role=config["role"],
            goal=config["goal"],
            backstory=config["backstory"],
            allow_delegation=False, # Strictement interdit
            verbose=self._verbose,
            tools=tools,
            llm=self._llm,
            max_iter=config.get("max_iter", 15)
        )

    def _process_outputs(
        self, 
        run_id: str, 
        crew_output: Any, 
        questionnaire: Dict[str, Any],
        persona: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Parse les outputs, sauvegarde en YAML et retourne le r√©sultat final."""
        
        run_dir = self._output_dir / run_id
        
        # Sauvegarde seulement en DEV
        should_save = settings.environment.lower() == "development"
        if should_save:
            run_dir.mkdir(parents=True, exist_ok=True)

        tasks_data = []
        normalized_trip = {}

        # Traitement des t√¢ches individuelles
        if hasattr(crew_output, "tasks_output"):
            for task_out in crew_output.tasks_output:
                task_name = getattr(task_out, "name", "unknown_task")
                raw_content = getattr(task_out, "raw", "")
                
                # Parsing YAML du contenu
                structured_content = self._parse_yaml_content(raw_content)
                
                task_record = {
                    "task_name": str(task_name),
                    "agent": getattr(task_out, "agent", ""),
                    "structured_output": structured_content,
                    "raw_output": raw_content # On garde le raw au cas o√π
                }
                tasks_data.append(task_record)

                # Si c'est la derni√®re t√¢che, c'est notre output final
                if task_name == "trip_specifications_design":
                    if isinstance(structured_content, dict) and "normalized_trip_request" in structured_content:
                        normalized_trip = structured_content["normalized_trip_request"]
                    else:
                        normalized_trip = structured_content # Fallback

                if should_save:
                    self._write_yaml(run_dir / f"{task_name}.yaml", task_record)

        # Construction du r√©sultat final
        final_payload = {
            "run_id": run_id,
            "status": "success",
            "metadata": {
                "questionnaire_id": self._extract_id(questionnaire),
                "timestamp": "generated_now"
            },
            "input_context": {
                "questionnaire": questionnaire,
                "persona_inference": persona
            },
            "pipeline_output": {
                "normalized_trip_request": normalized_trip,
                "tasks_details": tasks_data
            }
        }

        if should_save:
            self._write_yaml(run_dir / "run_output.yaml", final_payload)
            logger.info(f"üíæ Outputs sauvegard√©s dans {run_dir}")

        return final_payload

    def _parse_yaml_content(self, content: str) -> Any:
        """Nettoie et parse une cha√Æne contenant potentiellement du YAML."""
        if not content:
            return None
            
        # Nettoyage des balises markdown ```yaml ... ```
        cleaned = re.sub(r"^```yaml\s*", "", content.strip())
        cleaned = re.sub(r"^```\s*", "", cleaned)
        cleaned = re.sub(r"\s*```$", "", cleaned)
        
        try:
            return yaml.safe_load(cleaned)
        except yaml.YAMLError:
            logger.warning("‚ö†Ô∏è Impossible de parser le YAML, retour du contenu brut.")
            return content

    def _write_yaml(self, path: Path, data: Any) -> None:
        """√âcrit un fichier YAML proprement."""
        try:
            with path.open("w", encoding="utf-8") as f:
                yaml.dump(data, f, allow_unicode=True, sort_keys=False, indent=2)
        except Exception as e:
            logger.error(f"Erreur √©criture fichier {path}: {e}")

    def _load_yaml_config(self, filename: str) -> Dict[str, Any]:
        path = self._config_dir / filename
        if not path.exists():
            raise FileNotFoundError(f"Config manquante: {path}")
        with path.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}

    def _generate_run_id(self, data: Dict[str, Any]) -> str:
        qid = self._extract_id(data)
        suffix = uuid4().hex[:8]
        return f"{qid}-{suffix}" if qid else f"run-{suffix}"

    def _extract_id(self, data: Dict[str, Any]) -> str:
        return str(data.get("id") or data.get("questionnaire_id") or "")

    def _build_default_llm(self) -> LLM:
        """Construit le LLM (OpenAI par d√©faut)."""
        # Simplification pour Phase 1 - on suppose OpenAI ou compatible
        return LLM(
            model=settings.model_name,
            api_key=settings.openai_api_key,
            temperature=settings.temperature
        )

# Instance globale
travliaq_crew_pipeline = CrewPipeline()

def run_pipeline_with_inputs(**kwargs):
    return travliaq_crew_pipeline.run(**kwargs)
